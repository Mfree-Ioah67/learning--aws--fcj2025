---
title: "AI/ML/GenAI on AWS Workshop"
date: 2025-11-15
weight: 3
chapter: false
pre: " <b> 4.3. </b> "
---

{{% notice warning %}}
⚠️ **Note:** The information below is for reference purposes only. Please **do not copy it verbatim** into your report, including this warning.
{{% /notice %}}

# Summary Report: "AI/ML/GenAI on AWS Workshop"

### Event Objectives

- Understand the AI/ML landscape and AWS services ecosystem in Vietnam
- Learn end-to-end machine learning with Amazon SageMaker
- Explore Generative AI capabilities with Amazon Bedrock
- Master prompt engineering and RAG (Retrieval-Augmented Generation) techniques
- Build practical AI/ML solutions using AWS services

### Event Details

- **Location**: AWS Vietnam Office
- **Date & Time**: 8:30 AM – 12:00 PM, Saturday, November 15, 2025

### Speakers & Coordinators

**Instructors:**

- **Lâm Tuấn Kiệt** – Senior DevOps Engineer, FPT Software – Amazon SageMaker and ML Services Overview
- **Đinh Lê Hoàng Anh** – Cloud Engineer Trainee, FCAJ Swinburne University of Technology – Amazon Bedrock and AWS AI/ML Services
- **Danh Hoàng Hiếu Nghị** – Fresher AI Engineer, Renova Cloud – Amazon Bedrock Agent Core, live demonstrations and hands-on guidance

**Coordinators:**

- **AWS Vietnam Community Team**
- **FCJ Program Leaders**

### Event Agenda

#### 8:30 – 9:00 AM: Welcome & Introduction

- Participant registration and networking
- Workshop overview and learning objectives
- Ice-breaker activity
- Overview of the AI/ML landscape in Vietnam

#### 9:00 – 10:30 AM: AWS AI/ML Services Overview

**Amazon SageMaker – End-to-end ML Platform**

- **Data Preparation and Labeling**:
  - SageMaker Data Wrangler for data preprocessing
  - Ground Truth for data labeling and annotation
  - Feature Store for feature management and reuse
- **Model Training, Tuning, and Deployment**:
  - Built-in algorithms and custom training scripts
  - Hyperparameter tuning with automatic model optimization
  - Model deployment options: real-time, batch, and serverless inference
  - A/B testing and multi-model endpoints
- **Integrated MLOps Capabilities**:

  - SageMaker Pipelines for ML workflow automation
  - Model Registry for version control and governance
  - Model Monitor for detecting data drift and model quality
  - Integration with CI/CD tools for continuous deployment

- **Live Demo**: SageMaker Studio walkthrough
  - Creating a notebook instance
  - Training a machine learning model
  - Deploying and testing the model endpoint

#### 10:30 – 10:45 AM: Coffee Break

- Networking and refreshments
- Q&A with AWS experts

#### 10:45 AM – 12:00 PM: Generative AI with Amazon Bedrock and AWS AI/ML Services

**AWS AI/ML Services Overview**

- **Amazon Rekognition**: Computer vision for image and video analysis
- **Amazon Translate**: Automatic text translation with neural machine translation
- **Amazon Textract**: Extract text and data from documents
- **Amazon Transcribe**: Automatic speech-to-text conversion
- **Amazon Polly**: Text-to-speech with natural-sounding voices
- **Amazon Comprehend**: Natural language processing and text analytics
- **Amazon Kendra**: Intelligent search service powered by ML
- **Amazon Lookout**: Anomaly detection for operational data
- **Amazon Personalize**: ML-powered recommendation engine

**Foundation Models: Claude, Llama, Titan**

- **Model Comparison & Selection Guide**:
  - Claude (Anthropic): Best for conversational AI and complex reasoning
  - Llama (Meta): Open-source flexibility and customization
  - Titan (Amazon): Cost-effective and AWS-native integration
  - Choosing the right model for your use case

**Prompt Engineering Techniques**

- **Effective Prompting Strategies**:
  - Clear instructions and context setting
  - Few-shot learning with examples
  - Chain-of-Thought (CoT) reasoning for complex tasks
  - Role-based prompting and persona definition
- **Advanced Techniques**:
  - Temperature and token control
  - System prompts vs user prompts
  - Prompt templates and reusability

**Retrieval-Augmented Generation (RAG)**

- **RAG Architecture**:
  - Vector databases and embeddings
  - Semantic search and document retrieval
  - Context injection into prompts
- **Knowledge Base Integration**:
  - Amazon Bedrock Knowledge Bases
  - **Amazon S3** for storing documents and knowledge base data
  - Connecting to data sources (S3 buckets, databases, APIs)
  - Chunking strategies and metadata management
  - S3 bucket policies and access control for secure data storage

**Amazon Bedrock Agent Core**

- **Agent Orchestration**:
  - Bedrock Agent Core for building autonomous AI agents
  - Multi-step reasoning and task planning
  - Action groups and API integrations
  - Memory and conversation state management
- **Tool Integrations**:
  - **AWS Lambda** functions as tools for custom business logic
  - Lambda integration for real-time data processing
  - External API connections via Lambda
  - Database queries and data retrieval through Lambda
  - Serverless architecture benefits with Lambda + Bedrock

**Guardrails: Safety and Content Filtering**

- Content moderation and toxicity detection
- PII (Personally Identifiable Information) filtering
- Topic-based filtering and denied topics
- Custom guardrails for business requirements

**Live Demo: Building a Generative AI Chatbot using Bedrock**

- Setting up Bedrock foundation model access
- Creating a simple chatbot with prompt engineering
- Implementing RAG with Knowledge Bases
- Adding guardrails for safe responses
- Testing and iterating on the chatbot

### Key Takeaways

#### Amazon SageMaker Capabilities

- **End-to-End ML Platform**: SageMaker provides all tools needed from data preparation to model deployment
- **MLOps Integration**: Built-in capabilities for automating and monitoring ML workflows
- **Scalability**: Easily scale from experimentation to production workloads
- **Cost Optimization**: Pay-as-you-go pricing with options for spot instances and serverless inference

#### Generative AI with Bedrock

- **Model Diversity**: Access to multiple foundation models without managing infrastructure
- **Prompt Engineering**: Critical skill for getting quality outputs from LLMs
- **RAG Architecture**: Combines the power of LLMs with your proprietary data
- **Safety First**: Guardrails ensure responsible AI deployment
- **Agent Capabilities**: Enable complex, multi-step AI workflows

#### Practical Implementation

- **Start with Use Cases**: Identify specific business problems AI/ML can solve
- **Experiment and Iterate**: Use SageMaker Studio for rapid prototyping
- **Leverage Pre-built Models**: Start with foundation models before custom training
- **Implement Guardrails**: Always prioritize safety and compliance
- **Monitor and Optimize**: Continuously track model performance and costs

### Applying to Work

- **Explore SageMaker**: Start with SageMaker Studio free tier to experiment with ML workflows
- **Build RAG Applications**: Implement knowledge base integration for domain-specific chatbots
- **Practice Prompt Engineering**: Develop effective prompting strategies for your use cases
- **Implement MLOps**: Automate ML pipelines using SageMaker Pipelines
- **Deploy Bedrock Agents**: Create intelligent agents for automating business processes
- **Ensure Compliance**: Use Bedrock Guardrails to meet regulatory requirements
- **Share Knowledge**: Document learnings and best practices with your team

### Event Experience

Attending the **"AI/ML/GenAI on AWS Workshop"** at AWS Vietnam Office was an immersive learning experience that provided hands-on exposure to cutting-edge AI/ML technologies. Key experiences included:

#### Learning from AWS Experts

- **AWS Solutions Architects** provided comprehensive insights into SageMaker's end-to-end ML capabilities
- **AWS GenAI Specialists** demonstrated practical applications of Amazon Bedrock and foundation models
- Real-world use cases illustrated how Vietnamese companies are leveraging AWS AI/ML services
- Expert guidance on choosing the right tools and models for specific business needs

#### Hands-on Demonstrations

- Witnessed **SageMaker Studio** in action, from data preparation to model deployment
- Saw how **Amazon Bedrock** enables rapid development of GenAI applications without infrastructure management
- Learned practical **prompt engineering** techniques that immediately improve LLM outputs
- Explored **RAG architecture** for building knowledge-aware AI applications
- Understood how **Bedrock Agents** orchestrate complex multi-step workflows

#### Understanding AI/ML Landscape

- Gained insights into the **AI/ML adoption trends** in Vietnam
- Learned about the **differences between traditional ML and Generative AI** approaches
- Understood when to use **SageMaker vs Bedrock** for different use cases
- Discovered the importance of **MLOps** for production ML systems

#### Networking and Community Building

- Connected with fellow developers and data scientists exploring AWS AI/ML services
- Exchanged ideas about practical AI/ML implementation challenges and solutions
- Built relationships with AWS experts for ongoing support and guidance
- Joined the AWS AI/ML community for continuous learning

#### Practical Insights Gained

- **Foundation models** democratize access to powerful AI capabilities without requiring massive resources
- **Prompt engineering** is a critical skill that significantly impacts GenAI application quality
- **RAG architecture** solves the problem of LLMs lacking domain-specific knowledge
- **Guardrails** are essential for responsible and compliant AI deployment
- **SageMaker** provides a complete platform that accelerates ML development and deployment

#### Next Steps

- Begin experimenting with **SageMaker Studio** using the free tier
- Build a proof-of-concept **RAG application** using Bedrock Knowledge Bases
- Practice **prompt engineering** techniques on different foundation models
- Explore **Bedrock Agents** for automating business workflows
- Implement **MLOps practices** using SageMaker Pipelines
- Continue engaging with the **AWS AI/ML community** for ongoing learning

#### Some event photos

<p align="center"><img src="z7226089182052_a87c70d3e5127727e468ec919746aa14.jpg" alt="Lâm Tuấn Kiệt presenting Amazon SageMaker" width="600"/></p>
<hr>
<p align="center"><img src="z7226089182835_fd058a0d2646ba5ff862659b2a851ae3.jpg" alt="Lâm Tuấn Kiệt introducing ML Services" width="600"/></p>
<hr>
<p align="center"><img src="z7226089185538_6584042d4867f420dcdf26fbcd02f0d1.jpg" alt="Lâm Tuấn Kiệt demonstrating SageMaker Studio" width="600"/></p>
<hr>
<p align="center"><img src="z7226089188785_2f1d4536d4d2edb5bd8521822269e0d7.jpg" alt="Lâm Tuấn Kiệt explaining MLOps" width="600"/></p>
<hr>
<p align="center"><img src="z7226089195549_6134c1712f06d5fb6b0548a7a64e9750.jpg" alt="Đinh Lê Hoàng Anh presenting Amazon Bedrock" width="600"/></p>
<hr>
<p align="center"><img src="z7226089198697_2575442063921150c411a74a9edc32fc.jpg" alt="Đinh Lê Hoàng Anh introducing Foundation Models" width="600"/></p>
<hr>
<p align="center"><img src="z7226089200374_4b9ccc01a946fe9ed479a97f20ad5505.jpg" alt="Đinh Lê Hoàng Anh demonstrating Prompt Engineering" width="600"/></p>
<hr>
<p align="center"><img src="z7226089200375_950fb4714f844f7be177194a7e37a3a7.jpg" alt="Đinh Lê Hoàng Anh explaining RAG Architecture" width="600"/></p>
<hr>
<p align="center"><img src="z7226089203525_3469cd3ec7d62c0017a5263da64eff32.jpg" alt="Danh Hoàng Hiếu Nghị demonstrating Bedrock Agents" width="600"/></p>
<hr>
<p align="center"><img src="z7226089204044_8ce2e2975e24f9819d49e65be4db11c5.jpg" alt="Danh Hoàng Hiếu Nghị showing Guardrails" width="600"/></p>
<hr>
<p align="center"><img src="z7226089206129_2c222262ed586da5b52d7b6030a4c290.jpg" alt="Danh Hoàng Hiếu Nghị building GenAI Chatbot" width="600"/></p>
<hr>
<p align="center"><img src="z7226089216695_6b73693cec27aa10336add1ef9a03555.jpg" alt="Danh Hoàng Hiếu Nghị hands-on guidance" width="600"/></p>
<hr>
<p align="center"><img src="z7226089218316_67802975e0cb2fd27eca5753c983b534.jpg" alt="Participants networking" width="600"/></p>
<hr>
<p align="center"><img src="z7226089218462_0e1235918301fc52b7c887a7ea1096f0.jpg" alt="Group discussions" width="600"/></p>
<hr>
<p align="center"><img src="z7226089346755_df5c575289ae1e889d41530a7fa23152.jpg" alt="Networking session" width="600"/></p>
<hr>
<p align="center"><img src="z7226089354417_4443e34ead3ca15caf40177f0f9f49fc.jpg" alt="Q&A with speakers" width="600"/></p>
<hr>
<p align="center"><img src="z7226089356840_d7bda4bcca7392f3f9556ae7caa637ef.jpg" alt="Hands-on practice" width="600"/></p>
<hr>
<p align="center"><img src="z7226089356841_3c998c403886d96d8baf709f4dd4e5b6.jpg" alt="Workshop atmosphere" width="600"/></p>
<hr>
<p align="center"><img src="z7226089359526_87729a069d3be3043972c2c282e0becf.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089360189_8d1b4512bf90f8903f0734fe096ecb90.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089363728_27d9d0b068a8848a7a785090e98a754b.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089363826_ba00915e1e271ea506cf280d71ae827d.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089366343_1c4a98050cab1358bc27dab7a80a30f1.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089372751_ee454114f82defa27d40fe7e7aa52754.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089376197_63dd66304899769457969cade64e530e.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089380342_06bc2cb44d6cb83846a4e7c1439da961.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089383771_75be752db48944cbb444abe055a5371f.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089385022_19d8d1f46dfd4a6d96f3df63cf28a66b.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089387809_43295d0a2232a6f931293789e9b67e92.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089394453_f5dfbd223cf4d77fb7d75a8219d136b3.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089394608_8ddbe6d08a035fa4f121c1d0ebce372e.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089400963_b53f90b1d0b891779316d6b8123d0637.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089401010_47235c5b5898dbe77edd8d9294b8dac8.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089406027_4e19736efe7e840ce9e3412d682d06a7.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089411924_8f2a33fdef076d4a9ac07e59ae723840.jpg" alt="Event photo" width="600"/></p>
<hr>
<p align="center"><img src="z7226089412672_0d8e8c7c237589eda3e2b20edffa4dd7.jpg" alt="Event photo" width="600"/></p>

> Overall, this workshop provided a comprehensive introduction to AWS AI/ML services, from traditional machine learning with SageMaker to cutting-edge Generative AI with Bedrock. The hands-on demonstrations and expert guidance made complex concepts accessible and immediately applicable. The key takeaway is that AWS provides a complete ecosystem for building, deploying, and scaling AI/ML applications, making it easier than ever to bring AI innovations to production.
